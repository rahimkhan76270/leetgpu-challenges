<p>
  Implement a program that performs element-wise addition of two vectors containing 32-bit floating point numbers on a
  GPU.
  The program should take two input vectors of equal length and produce a single output vector containing their sum.
</p>

<h2>Implementation Requirements</h2>
<ul>
  <li>External libraries are not permitted</li>
  <li>The <code>solve</code> function signature must remain unchanged</li>
  <li>The final result must be stored in vector <code>C</code></li>
</ul>

<h2>Example 1:</h2>
<pre>
Input:  A = [1.0, 2.0, 3.0, 4.0]
        B = [5.0, 6.0, 7.0, 8.0]
Output: C = [6.0, 8.0, 10.0, 12.0]
</pre>

<h2>Example 2:</h2>
<pre>
Input:  A = [1.5, 1.5, 1.5]
        B = [2.3, 2.3, 2.3]
Output: C = [3.8, 3.8, 3.8]
</pre>

<h2>Constraints</h2>

<ul>
  <li>Input vectors <code>A</code> and <code>B</code> have identical lengths</li>
  <li>1 &le; <code>N</code> &le; 100,000,000</li>
</ul>